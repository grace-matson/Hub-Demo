{
  "parents": [
    "system:cdap-data-pipeline[4.3.0-SNAPSHOT,4.4.0-SNAPSHOT)",
    "system:cdap-data-streams[4.3.0-SNAPSHOT,4.4.0-SNAPSHOT)"
  ],
  "properties": {
    "widgets.SolrSearch-batchsink": "{\"metadata\":{\"spec-version\":\"1.5\"},\"display-name\":\"Solr Search\",\"configuration-groups\":[{\"label\":\"Solr Search Configuration\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Reference Name\",\"name\":\"referenceName\"},{\"widget-type\":\"select\",\"label\":\"Solr Mode\",\"name\":\"solrMode\",\"widget-attributes\":{\"values\":[\"SingleNode\",\"SolrCloud\"],\"default\":\"SingleNode\"}},{\"widget-type\":\"csv\",\"label\":\"Solr Host\",\"name\":\"solrHost\"},{\"widget-type\":\"textbox\",\"label\":\"Collection\",\"name\":\"collectionName\"},{\"widget-type\":\"textbox\",\"label\":\"Key Field\",\"name\":\"keyField\"},{\"widget-type\":\"number\",\"label\":\"Batch Size\",\"name\":\"batchSize\",\"widget-attributes\":{\"default\":\"10000\"}},{\"widget-type\":\"keyvalue\",\"label\":\"Fields to rename\",\"name\":\"outputFieldMappings\",\"widget-attributes\":{\"showDelimiter\":\"false\",\"key-placeholder\":\"Field Name\",\"value-placeholder\":\"New Field Name\"}}]}],\"outputs\":[]}",
    "doc.SolrSearch-batchsink": "# SolrSearch Batch Sink\n\n\nDescription\n-----------\nThe Solr search batch sink takes the structured record from the input source and indexes it into the Solr server or\nSolrCloud using the collection and key field specified by the user.\n\nThe incoming fields from the previous stage in pipelines are mapped to Solr fields. Also, user is able to specify the\nmode of the Solr to connect to. For example, SingleNode Solr or SolrCloud.\n\nUse Case\n--------\nSolr search batch sink is used to write data to the Solr server or SolrCloud. For example, the plugin can be used in\nconjuction with a stream batch source to parse a file and read its contents in Solr.\n\nProperties\n----------\n**referenceName:** This will be used to uniquely identify this sink for lineage, annotating metadata, etc.\n\n**solrMode:** Solr mode to connect to. For example, SingleNode Solr or SolrCloud.\n\n**solrHost:** The hostname and port for the Solr server. For example, localhost:8983 if SingleNode Solr or\nzkHost1:2181,zkHost2:2181,zkHost3:2181 for SolrCloud.\n\n**collectionName:** Name of the collection where data will be indexed and stored in Solr.\n\n**keyField:** Field that will determine the unique key for the document to be indexed. It must match a field name\nin the structured record of the input.\n\n**batchSize:** Number of documents to create a batch and send it to Solr for indexing. After each batch, commit will\nbe triggered. Default batch size is 10000. (Macro-enabled)\n\n**outputFieldMappings:** List of the input fields to map to the output Solr fields. This is a comma-separated list of\nkey-value pairs, where each pair is separated by a colon ':' and specifies the input and output names. For example,\n'firstname:fname,lastname:lname' specifies that the 'firstname' should be renamed to 'fname' and the 'lastname'\nshould be renamed to 'lname'.\n\nConditions\n----------\nThe Solr server should be running prior to creating the application.\n\nAll the fields that user wants to index into the Solr server, should be properly declared and defined in Solr's\nschema.xml file. The Solr server schema should be properly defined prior to creating the application.\n\nIf keyField('id') in the input record is NULL, then that particular record will be filtered out.\n\nExample\n-------\nThis example connects to a 'SinlgeNode Solr' server, running locally at the default port of 8983, and writes the\ndata to the specified collection (test_collection). The data is indexed using the id field coming in the input record\n. And also the fieldname 'office address' is mapped to the 'address' field in Solr's index.\n\n    {\n      \"name\": \"SolrSearch\",\n      \"type\": \"batchsink\",\n        \"properties\": {\n          \"solrMode\": \"SingleNode\",\n          \"solrHost\": \"localhost:8983\",\n          \"collectionName\": \"test_collection\",\n          \"keyField\": \"id\",\n          \"batchSize\": \"10000\",\n          \"outputFieldMappings\": \"office address:address\"\n        }\n    }\n\nFor example, suppose the Solr search sink receives the input record:\n\n    +===================================================================================================+\n    | id : STRING | firstname : STRING  | lastname : STRING |  office address : STRING  | pincode : INT |\n    +===================================================================================================+\n    | 100A        | John                | Wagh              |  NE Lakeside              | 480001        |\n    | 100B        | Brett               | Lee               |  SE Lakeside              | 480001        |\n    +===================================================================================================+\n\n Once Solr search sink plugin execution is completed, all the rows from input data will be indexed in the\n test_collection with the fields id, firstname, lastname, address and pincode."
  }
}