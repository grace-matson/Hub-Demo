{
  "parents": [
    "system:cdap-data-pipeline[4.1.0,4.2.0-SNAPSHOT)",
    "system:cdap-data-streams[4.1.0,4.2.0-SNAPSHOT)"
  ],
  "properties": {
    "widgets.HiveExport-action": "{\"metadata\":{\"spec-version\":\"1.0\"},\"configuration-groups\":[{\"label\":\"General\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Hive Metastore Username\",\"name\":\"user\"},{\"widget-type\":\"password\",\"label\":\"Hive Metastore Password\",\"name\":\"password\"},{\"widget-type\":\"textbox\",\"label\":\"JDBC Connection String\",\"name\":\"connectionString\",\"widget-attributes\":{\"placeholder\":\"jdbc:hive2://localhost:10000/mydb;auth=delegationToken\"}},{\"widget-type\":\"textarea\",\"label\":\"Select Statement\",\"name\":\"statement\",\"widget-attributes\":{\"placeholder\":\"SELECT * FROM employee e JOIN salary s ON (e.id = s.id)\"}},{\"widget-type\":\"textbox\",\"label\":\"Output Directory\",\"name\":\"path\",\"widget-attributes\":{\"placeholder\":\"/path/to/export/directory\"}},{\"widget-type\":\"select\",\"label\":\"Overwrite Output Directory\",\"name\":\"overwrite\",\"widget-attributes\":{\"values\":[\"yes\",\"no\"],\"default\":\"yes\"}},{\"widget-type\":\"textbox\",\"label\":\"Column Separator\",\"name\":\"delimiter\",\"widget-attributes\":{\"default\":\",\"}}]}]}",
    "widgets.HiveImport-action": "{\"metadata\":{\"spec-version\":\"1.0\"},\"configuration-groups\":[{\"label\":\"General\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Hive Metastore Username\",\"name\":\"user\"},{\"widget-type\":\"password\",\"label\":\"Hive Metastore Password\",\"name\":\"password\"},{\"widget-type\":\"textbox\",\"label\":\"JDBC Connection String\",\"name\":\"connectionString\",\"widget-attributes\":{\"placeholder\":\"jdbc:hive2://localhost:10000/mydb;auth=delegationToken\"}},{\"widget-type\":\"textarea\",\"label\":\"Statement to Load data into hive\",\"name\":\"statement\",\"widget-attributes\":{\"placeholder\":\"LOAD DATA INPATH '/tmp/hive' INTO TABLE testTable\"}}]}]}",
    "doc.HiveExport-action": "# HiveExport Action\n\n\nDescription\n-----------\nHive Export will take select query as input to run that query on hive table and store results under provided HDFS directory. When the select query is provided to the plugin,\nit converts that select query to [INSERT OVERWRITE DIRECTORY](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML) hive statement.\nWhen this query is executed, hive starts a mapreduce job which stores the results to provided directory location. So there can be multiple files in\na given directory location. Hive Export works with hive 1.2.1.\n\nIf any query other than a valid SELECT query is provided, Hive Export will fail to publish the pipeline. This is becuase we use [Apache Calcite](https://calcite.apache.org/)\nto parse the SELECT query to verify that its not any other SQL Query.\n\nTo run the SELECT query, if `Overwrite Output Directory` property is set to `no`, the pipeline publish will fail if the output directory already exists. In that case,\nplease either remove the directory or allow directory to be overwritten by specifying `Overwrite Output Directory` property to `yes`.\n\nUse Case\n--------\nHive Export Action executes a select query on hive table(s) and writes results in a provided directory location in csv format.\n\n\nProperties\n----------\n\n**user:** User identity for connecting to the specified hive database. Required for databases that need\nauthentication. Optional for databases that do not require authentication.\n\n**password:** Password to use to connect to the specified database. Required for databases\nthat need authentication. Optional for databases that do not require authentication.\n\n**connectionString:** JDBC connection string including database name. Please use auth=delegationToken, \nCDAP platform will provide appropriate delegation token while running the pipeline. \n\n**statement:** Select command to select values from hive table(s).\n\n**path:** HDFS Directory path where exported data will be written. If it does not exist it will get created. \nIf it already exists, we can either overwrite it or fail at publish time based on `Overwrite Output Directory` property.\n\n**overwrite:** If yes is selected, if the HDFS `path` exists, it will be overwritten. If no is selected, if the HDFS path exists,\n pipeline deployment will fail while publishing the pipeline.\n\n**delimiter:** Delimiter in the exported file. Values in each column is separated by this delimiter while writing \nto output file. By default, it uses comma.\n\n\nExample\n-------\nThis example connects to a hive database using the specified 'connectionString', which means\nit will connect to the 'mydb' database of a hive instance running on 'localhost' and runs the \nselect query as 'INSERT OVERWRITE DIRECTORY' statement. It will use path directory /tmp/hive and delimiter comma\nto write data into file(s).\n\n    {\n        \"name\": \"HiveExport\",\n        \"plugin\": {\n            \"name\": \"HiveExport\",\n            \"type\": \"action\",\n            \"properties\": {\n                \"path\": \"/tmp/hive\",\n                \"overwrite\": \"yes\",\n                \"delimiter\": \",\",\n                \"user\": \"username\",\n                \"password\": \"password\",\n                \"connectionString\": \"jdbc:hive2://localhost:10000/mydb;auth=delegationToken\",\n                \"statement\": \"SELECT * FROM employee JOIN salary ON (employee.id = salary.id)\"\n            }\n        }\n    }\n",
    "doc.HiveImport-action": "# HiveImport Action\n\n\nDescription\n-----------\nImports data from hdfs directory/file into a hive table. Hive Import Action imports data from HDFS by executing provided Hive [Load Statement](https://cwiki.apache.org/confluence/display/Hive/GettingStarted). \nLocal file storage is not allowed because a pipeline can run on any machine. If `LOCAL` file storage option is provided,\npipeline deployment fails at publish time. Hive Import only accepts hive `LOAD` statements. If any other hive query is provided,\npipeline publish will fail. If the Load command is executed successfully, all the files in the directory will be moved, not copied, to hive/warehouse directory. Hive import works with Hive 1.2.1.\n\n\nUse Case\n--------\nHive Import Action executes a hive load statement which loads data from HDFS file/directory location into a hive table.\n\n\nProperties\n----------\n\n**user:** User identity for connecting to the specified hive database. Required for databases that need\nauthentication. Optional for databases that do not require authentication.\n\n**password:** Password to use to connect to the specified database. Required for databases\nthat need authentication. Optional for databases that do not require authentication.\n\n**connectionString:** JDBC connection string including database name. Please use auth=delegationToken, \nCDAP platform will provide appropriate delegation token while running the pipeline. \n\n**statement:** Load command to load files data into a hive table. `LOCAL` option in `LOAD` command is not available.\n\n\nExample\n-------\nThis example connects to a hive database using the specified 'connectionString', which means\nit will connect to the 'mydb' database of a hive instance running on 'localhost' and runs the \nload query. This plugin will read all the files from HDFS path /tmp/hive and load data\nto table testTable.\n\n    {\n        \"name\": \"HiveExportAction\",\n        \"plugin\": {\n            \"name\": \"HiveExportAction\",\n            \"type\": \"action\",\n            \"properties\": {\n                \"user\": \"username\",\n                \"password\": \"password\",\n                \"connectionString\": \"jdbc:hive2://localhost:10000/mydb;auth=delegationToken\",\n                \"statement\": \"LOAD DATA INPATH '/tmp/hive' INTO TABLE testTable\"\n            }\n        }\n    }\n",
    "doc.README-HIVE-EXPORT": "[![Build Status](https://travis-ci.org/hydrator/hive-plugins.svg?branch=master)](https://travis-ci.org/hydrator/hive-plugins) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nHive Export\n===========\n\nHive Export will export data from hive table(s) and store them in csv format at a given directory location on HDFS.\n\n<img align=\"center\" src=\"hive-export.png\"  width=\"400\" alt=\"plugin configuration\" />\n\nUsage Notes\n-----------\n\nHive Export will take select query as input to run that query on hive table and store results under provided HDFS directory. When the select query is provided to the plugin,\nit converts that select query to [INSERT OVERWRITE DIRECTORY](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML) hive statement.\nWhen this query is executed, hive starts a mapreduce job which stores the results to provided directory location. So there can be multiple files in\na given directory location. Hive Export works with hive 1.2.1.\n\nIf any query other than a valid SELECT query is provided, Hive Export will fail to publish the pipeline. This is becuase we use [Apache Calcite](https://calcite.apache.org/)\nto parse the SELECT query to verify that its not any other SQL Query.\n\nTo run the SELECT query, if `Overwrite Output Directory` property is set to `no`, the pipeline publish will fail if the output directory already exists. In that case,\nplease either remove the directory or allow directory to be overwritten by specifying `Overwrite Output Directory` property to `yes`.\n\nPlugin Configuration\n---------------------\n\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :----- | :---------- |\n| **Hive Metastore Username** | **N** | N/A | User identity for connecting to the specified hive database. Required for databases that need authentication. Optional for databases that do not require authentication. |\n| **Hive Metastore Password** | **N** | N/A | Password to use to connect to the specified database. Required for databases that need authentication. Optional for databases that do not require authentication. |\n| **JDBC Connection String** | **Y** | N/A | JDBC connection string including database name. Please use auth=delegationToken, CDAP platform will provide appropriate delegation token while running the pipeline. |\n| **Select Statement** | **Y** | N/A | Valid select command to select values from a hive table. |\n| **Output Directory** | **Y** | N/A | HDFS Directory path where exported data will be written. If it does not exist it will get created. If it already exists, we can either overwrite it or fail at publish time based on `Overwrite Output Directory` property. |\n| **Overwrite Output Directory** | **Y** | yes | If yes is selected, if the HDFS `path` exists, it will be overwritten. If no is selected, if the HDFS path exists, pipeline deployment will fail while publishing the pipeline. |\n| **Column Separator** | **Y** | , | Delimiter in the exported file. Values in each column is separated by this delimiter while writing to output file. By default, it uses comma.  |\n\nBuild\n-----\nTo build this plugin:\n\n```\n   mvn clean package\n```    \n\nThe build will create a .jar and .json file under the ``target`` directory.\nThese files can be used to deploy your plugins.\n\nDeployment\n----------\nYou can deploy your plugins using the CDAP CLI:\n\n    > load artifact <target/hive-plugins-<version>.jar config-file <target/hive-plugins<version>.json>\n\nFor example, if your artifact is named 'hive-plugins-<version>':\n\n    > load artifact target/hive-plugins-<version>.jar config-file target/hive-plugins-<version>.json\n    \n## Mailing Lists\n\nCDAP User Group and Development Discussions:\n\n* `cdap-user@googlegroups.com <https://groups.google.com/d/forum/cdap-user>`\n\nThe *cdap-user* mailing list is primarily for users using the product to develop\napplications or building plugins for appplications. You can expect questions from \nusers, release announcements, and any other discussions that we think will be helpful \nto the users.\n\n\n## License and Trademarks\n\nCopyright © 2017 Cask Data, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\nin compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the \nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \neither express or implied. See the License for the specific language governing permissions \nand limitations under the License.\n\nCask is a trademark of Cask Data, Inc. All rights reserved.\n\nApache, Apache HBase, and HBase are trademarks of The Apache Software Foundation. Used with\npermission. No endorsement by The Apache Software Foundation is implied by the use of these marks.      \n",
    "doc.README-HIVE-IMPORT": "[![Build Status](https://travis-ci.org/hydrator/hive-plugins.svg?branch=master)](https://travis-ci.org/hydrator/hive-plugins) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nHive Import\n===========\n\nHive Import Action executes a hive load statement which loads data from HDFS directory/file location into a hive table.\n\n<img align=\"center\" src=\"hive-import.png\"  width=\"400\" alt=\"plugin configuration\" />\n\nUsage Notes\n-----------\n\nHive Import Action imports data from HDFS by executing provided Hive [Load Statement](https://cwiki.apache.org/confluence/display/Hive/GettingStarted). \nLocal file storage is not allowed because a pipeline can run on any machine. If `LOCAL` file storage option is provided,\npipeline deployment fails at publish time. Hive Import only accepts hive `LOAD` statements. If any other hive query is provided,\npipeline publish will fail. \n\nIf the Load command is executed successfully, all the files in the directory will be moved, not copied, to hive/warehouse directory. Hive import works with Hive 1.2.1.\n\nPlugin Configuration\n---------------------\n\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :----- | :---------- |\n| **Hive Metastore Username** | **N** | N/A | User identity for connecting to the specified hive database. Required for databases that need authentication. Optional for databases that do not require authentication. |\n| **Hive Metastore Password** | **N** | N/A | Password to use to connect to the specified database. Required for databases that need authentication. Optional for databases that do not require authentication. |\n| **JDBC Connection String** | **Y** | N/A | JDBC connection string including database name. Please use auth=delegationToken, CDAP platform will provide appropriate delegation token while running the pipeline. |\n| **Statement to Load data into hive** | **Y** | N/A | Load command to load files data into a hive table. `LOCAL` option in `LOAD` command is not available. |\n\nBuild\n-----\nTo build this plugin:\n\n```\n   mvn clean package\n```    \n\nThe build will create a .jar and .json file under the ``target`` directory.\nThese files can be used to deploy your plugins.\n\nDeployment\n----------\nYou can deploy your plugins using the CDAP CLI:\n\n    > load artifact <target/hive-plugins-<version>.jar config-file <target/hive-plugins<version>.json>\n\nFor example, if your artifact is named 'hive-plugins-<version>':\n\n    > load artifact target/hive-plugins-<version>.jar config-file target/hive-plugins-<version>.json\n    \n## Mailing Lists\n\nCDAP User Group and Development Discussions:\n\n* `cdap-user@googlegroups.com <https://groups.google.com/d/forum/cdap-user>`\n\nThe *cdap-user* mailing list is primarily for users using the product to develop\napplications or building plugins for appplications. You can expect questions from \nusers, release announcements, and any other discussions that we think will be helpful \nto the users.\n\n\n## License and Trademarks\n\nCopyright © 2017 Cask Data, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\nin compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the \nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \neither express or implied. See the License for the specific language governing permissions \nand limitations under the License.\n\nCask is a trademark of Cask Data, Inc. All rights reserved.\n\nApache, Apache HBase, and HBase are trademarks of The Apache Software Foundation. Used with\npermission. No endorsement by The Apache Software Foundation is implied by the use of these marks.      \n"
  }
}